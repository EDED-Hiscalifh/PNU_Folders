{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd21c2b",
   "metadata": {},
   "source": [
    "# 1. Linear Model \n",
    "\n",
    "## 1.1 OLS model\n",
    "\n",
    "- The linear regresssion model : $Y = \\beta_0 + \\beta_1 X_1 + ... \\beta_p X_p + \\epsilon$\n",
    "- OLS \n",
    "    - **Ordinary least squared (OLS)** is a type of linear least squares method for estimating the unkown parameters in a linear regression. \n",
    "    - All parameters of OLS model are unbiased estimators \n",
    "    - $E(\\hat{\\beta}^{OLS}) = \\beta$\n",
    "    - $Var(\\hat{\\beta}^{OLS}) ↓$\n",
    "    - Problems in multiple linear regression \n",
    "        - OLS cannot be computed when n < p (high-dimensional data). \n",
    "        - OLS has relatively large variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02079eca",
   "metadata": {},
   "source": [
    "## 1.2 [Ex] Ordinary Least Squares(OLS) \n",
    "\n",
    "```R\n",
    "set.seed(123)\n",
    "n <- 100\n",
    "# pp : pp means the number of samples \n",
    "pp <- c(10, 50, 80, 95, 97, 98, 99)\n",
    "B <- matrix(0, 100, length(pp))\n",
    "\n",
    "\n",
    "for (i in 1:100) {\n",
    "  for (j in 1:length(pp)) {\n",
    "    beta <- rep(0, pp[j])\n",
    "    # beta1 == 1, beta0, beta2, ... betap -> 0 \n",
    "    beta[1] <- 1\n",
    "    x <- matrix(rnorm(n*pp[j]), n, pp[j])\n",
    "    # x %*% beta is same as x[, 1]\n",
    "    y <- x %*% beta + rnorm(n)\n",
    "    g <- lm(y~x)\n",
    "    B[i,j] <- g$coef[2]\n",
    "  }\n",
    "}\n",
    "boxplot(B, col=\"orange\", boxwex=0.6, ylab=\"Coefficient estimates\",\n",
    "        names=pp, xlab=\"The number of predictors\", ylim=c(-5,5))\n",
    "abline(h=1, col=2, lty=2, lwd=2)\n",
    "apply(B, 2, mean)\n",
    "apply(B, 2, var)\n",
    "```\n",
    "\n",
    "![](Img/OLS01.png)\n",
    "\n",
    "- This means the mean of $\\hat{\\beta}^{OLS}$ is located 1 approximately. \n",
    "- If the number of variable is increasing(p is increasing), then the variance becomes higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74b3ef",
   "metadata": {},
   "source": [
    "## 1.3 Three classes of solving problems \n",
    "\n",
    "- To solve the problem (variance become higher when the number of features is bigger), we need to make p lower than n. \n",
    "- **Subset Selection** : Identify a subset of the p predictors that we belive to be related to the response. \n",
    "- **Shrinkage** : Fit a model involving all p predictors, but the estimated coefficients are shrunken towards zero relative to the OLS estimates. \n",
    "- **Dimension Reduction** : Project the p predictors into a M-dimensional subspace. PCA is example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc079b0a",
   "metadata": {},
   "source": [
    "# 2. Subset Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27bf1a",
   "metadata": {},
   "source": [
    "## 2.1 Best subsets regression\n",
    "\n",
    "- The most direct approach is called **all subsets** or **best subsets regression**. \n",
    "- <font color=\"red\">Fit for all possible subsets and then choose model based on some criterion that balances **training error** with **model size**.</font> \n",
    "\n",
    "Let's consider when we want to make best subset model using 10 features. First, we make null model $M_0$, which contains no predictors. Next, for k = 1, 2, ... p, repeat the steps following : \n",
    "\n",
    "- Fit all $(p, k)$ models that contain exactly k predictors. (This models must have the same counts of predictors) \n",
    "- Pick the best among these $(p, k)$ models, and call it $M_k$. Here best is defined as having the smallest RSS, or equivalently largest $R^2$. (We only use RSS or $R^2$ when we pick the best model among $(p, k)$ models) \n",
    "- Select a single best model from among $M_0, M_1, ..., M_p$ using CVE, $C_p$, AIC, BIC, or adjusted $R^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0d07e",
   "metadata": {},
   "source": [
    "## 2.2 [Ex] Best subsets regression on Hitters \n",
    "\n",
    "\n",
    "```R\n",
    "library(ISLR)\n",
    "names(Hitters)\n",
    "dim(Hitters)\n",
    "sum(is.na(Hitters$Salary))\n",
    "Hitters <- na.omit(Hitters)\n",
    "dim(Hitters)\n",
    "sum(is.na(Hitters))\n",
    "library(leaps)\n",
    "fit <- regsubsets(Salary ~ ., Hitters)\n",
    "summary(fit)\n",
    "sg <- summary(fit)\n",
    "names(sg)\n",
    "dim(sg$which)\n",
    "sg$which\n",
    "plot(fit)\n",
    "plot(fit, scale=\"Cp\")\n",
    "```\n",
    "\n",
    "![](Img/BSR01.png)\n",
    "\n",
    "- regsubsets function calculate the best model among $(p, k)$ models. \n",
    "- The default values of parameter nbest and nvmax are 1 and 8 in each. \n",
    "- https://www.rdocumentation.org/packages/leaps/versions/3.1/topics/regsubsets\n",
    "\n",
    "![](Img/BSR02.png)\n",
    "\n",
    "- The number of parameters of best model is 8 while using metrics as $C_p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e0ec5",
   "metadata": {},
   "source": [
    "# 3. Choosing the Optimal Model \n",
    "\n",
    "- Metrics $RSS$ and $R^2$ are only used in choosing best model among $(p, k)$ models. \n",
    "- To choose a model with low test error, we need to consider two ways. \n",
    "    - Indirectly estimate test error : $C_p$, AIC, BIC, and adjusted $R^2$\n",
    "    - Directly estimate test error : CVE \n",
    "- Mallow's $C_p$ : $C_p = \\frac{1}{n}(RSS + 2d\\hat{\\sigma}^2)$. Trade off between RSS and $2d\\hat{\\sigma}^2$. This metric has penalty on the number of parameters. \n",
    "- AIC : $AIC = -2log(L) + 2d$\n",
    "- BIC : $BIC = \\frac{1}{n}(RSS + log(n)d\\hat{\\sigma}^2)$. This metric has penalty on the number of sample size. (If n > 8, then BIC > $C_p$)\n",
    "- Adjusted $R^2$ : scale RSS term by $\\frac{RSS}{n-d-1}$ which d is the number of parameter and n is the number of sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d36ae4",
   "metadata": {},
   "source": [
    "## 3.1 [Ex] Find the best model considering same model size (RSS, $R^2$)\n",
    "\n",
    "```R\n",
    "big <- regsubsets(Salary ~ ., data=Hitters, nvmax=19, nbest=10)\n",
    "sg <- summary(big)\n",
    "dim(sg$which)\n",
    "sg.size <- as.numeric(rownames(sg$which))\n",
    "table(sg.size)\n",
    "sg.rss <- tapply(sg$rss, sg.size, min)\n",
    "w1 <- which.min(sg.rss)\n",
    "sg.rsq <- tapply(sg$rsq, sg.size, max)\n",
    "w2 <- which.max(sg.rsq)\n",
    "par(mfrow=c(1,2))\n",
    "plot(1:19, sg.rss, type=\"b\", xlab=\"Number of Predictors\",\n",
    "     ylab=\"Residual Sum of Squares\", col=2, pch=19)\n",
    "points(w1, sg.rss[w1], pch=\"x\", col=\"blue\", cex=2)\n",
    "plot(1:19, sg.rsq, type=\"b\", xlab=\"Number of Predictors\",\n",
    "     ylab=expression(R^2), col=2, pch=19)\n",
    "points(w2, sg.rsq[w2], pch=\"x\", col=\"blue\", cex=2)\n",
    "```\n",
    "\n",
    "![](Img/metrics01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9eb8e8",
   "metadata": {},
   "source": [
    "## 3.2 [Ex] Find the best model considering different model size(AIC, BIC, Adjust $R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d23a6",
   "metadata": {},
   "source": [
    "```R\n",
    "sg.cp <- tapply(sg$cp, sg.size, min)\n",
    "w3 <- which.min(sg.cp)\n",
    "sg.bic <- tapply(sg$bic, sg.size, min)\n",
    "w4 <- which.min(sg.bic)\n",
    "sg.adjr2 <- tapply(sg$adjr2, sg.size, max)\n",
    "w5 <- which.max(sg.adjr2)\n",
    "par(mfrow=c(1,3))\n",
    "plot(1:19, sg.cp, type=\"b\", xlab =\"Number of Predictors\",\n",
    "     ylab=expression(C[p]), col=2, pch=19)\n",
    "points(w3, sg.cp[w3], pch=\"x\", col=\"blue\", cex=2)\n",
    "plot(1:19, sg.bic, type=\"b\", xlab =\"Number of Predictors\",\n",
    "     ylab=\"Bayesian information criterion\", col=2, pch=19)\n",
    "points(w4, sg.bic[w4], pch=\"x\", col=\"blue\", cex=2)\n",
    "plot(1:19, sg.adjr2, type=\"b\", xlab =\"Number of Predictors\",\n",
    "     ylab=expression(paste(\"Adjusted \", R^2)), col=2, pch=19)\n",
    "points(w5, sg.adjr2[w5], pch=\"x\", col=\"blue\", cex=2)\n",
    "```\n",
    "\n",
    "![](Img/metrics02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b87b8",
   "metadata": {},
   "source": [
    "## 3.3 [Ex] Find the best model considering Validation set\n",
    "\n",
    "- Consider $RSS$ and $R^2$ among models with same sample size : $M_k$\n",
    "- Consider $C_p$, $AIC$, $BIC$, and $Adjust R^2$ among models with different sample size \n",
    "- To find best model among $M_k$ models, we divide sample size into train size and test size. (The test size shouldn't be trained to train model.) \n",
    "\n",
    "```R\n",
    "library(ISLR)\n",
    "library(leaps)\n",
    "names(Hitters)\n",
    "Hitters <- na.omit(Hitters)\n",
    "\n",
    "# Train-test split : Bootstrap (66%, 33%) \n",
    "set.seed(1234)\n",
    "train <- sample(c(TRUE, FALSE), nrow(Hitters), replace=TRUE) \n",
    "test <- (!train) \n",
    "\n",
    "# Training model \n",
    "# Consider RSS and R^2 among models with same sample size : find M_k \n",
    "g1 <- regsubsets(Salary ~ ., data=Hitters[train, ], nvmax=19) \n",
    "test.mat <- model.matrix(Salary~., data=Hitters[test, ]) \n",
    "val.errors <- rep(NA, 19)\n",
    "# Calculating validation error \n",
    "for (i in 1:19) {\n",
    "  coefi <- coef(g1, id=i) \n",
    "  pred <- test.mat[, names(coefi)] %*% coefi\n",
    "  val.errors[i] <- mean((Hitters$Salary[test]-pred)^2) \n",
    "}\n",
    "val.errors\n",
    "w <- which.min(val.errors) \n",
    "\n",
    "plot(1:19, val.errors, type=\"l\", col=\"red\",\n",
    "     xlab=\"Number of Predictors\", ylab=\"Validation Set Error\")\n",
    "points(1:19, val.errors, pch=19, col=\"blue\")\n",
    "points(w, val.errors[w], pch=\"x\", col=\"blue\", cex=2)\n",
    "```\n",
    "\n",
    "![](Img/Subset_CV_set.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36835554",
   "metadata": {},
   "source": [
    "## 3.4 [Ex] Find the best model considering K-fold CV\n",
    "\n",
    "- We can calculate K-fold CV by two ways. \n",
    "- Option 1 : Make error matrix of matrix(K, parameters) -> MAE -> apply(mat, 2, mean) \n",
    "- Option 2 : Make error matrix of matrix(n, parameters) -> E -> apply(mat, 2, mean) \n",
    "\n",
    "```R\n",
    "library(ISLR)\n",
    "names(Hitters)\n",
    "\n",
    "## Define new \"predict\" function on regsubset\n",
    "predict.regsubsets <- function(object, newdata, id, ...) {\n",
    "  form <- as.formula(object$call[[2]])\n",
    "  mat <- model.matrix(form, newdata)\n",
    "  coefi <- coef(object, id=id)\n",
    "  xvars <- names(coefi)\n",
    "  mat[, xvars] %*% coefi\n",
    "}\n",
    "\n",
    "# KFold Train-test split : Bootstrap (66%, 33%) using 10 folds \n",
    "set.seed(1234)\n",
    "K <- 10 \n",
    "folds <- sample(rep(1:K, length=nrow(Hitters))) \n",
    "\n",
    "# Initialize error matrix of every fold \n",
    "cv.errors <- matrix(NA, K, 19, dimnames=list(NULL, paste(1:19))) \n",
    "\n",
    "# Repeat calculation in ever 8 folds\n",
    "for (k in 1:K) { \n",
    "  train <- sample(c(TRUE, FALSE), nrow(Hitters), replace=TRUE) \n",
    "  test <- (!train) \n",
    "  \n",
    "  # Training model \n",
    "  # Consider RSS and R^2 among models with same sample size : find M_k \n",
    "  fit <- regsubsets(Salary ~ ., data=Hitters[folds!=k, ], nvmax=19) \n",
    "  \n",
    "  # Calculating validation error \n",
    "  for (i in 1:19) {\n",
    "    pred <- predict(fit, Hitters[folds==k, ], id=i) \n",
    "    cv.errors[k, i] <- mean((Hitters$Salary[folds==k]-pred)^2) \n",
    "  }\n",
    "} \n",
    "apply(cv.errors, 2, mean)\n",
    "K.ERR <- apply(cv.errors, 2, mean)\n",
    "ww <- which.min(K.ERR)\n",
    "\n",
    "# Visualize the test error\n",
    "plot(1:19, K.ERR, type=\"l\", col=\"red\",\n",
    "     xlab=\"Number of Predictors\", ylab=\"Cross-Validation Error\")\n",
    "points(1:19, K.ERR, pch=19, col=\"blue\")\n",
    "points(ww, K.ERR[ww], pch=\"x\", col=\"blue\", cex=2)\n",
    "```\n",
    "\n",
    "![](Img/Subset_Kfold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d9620",
   "metadata": {},
   "source": [
    "## 3.5 [Ex] Find the best model considering One-Standard Error Rules \n",
    "\n",
    "- Considering CVE as $(\\bar{X} - \\frac{\\hat{\\sigma}}{\\sqrt{n}}, \\bar{X} + \\frac{\\hat{\\sigma}}{\\sqrt{n}})$\n",
    "- Finding the best model roughly. \n",
    "- Refer the best model which mean of CVE is lower than the high upperbond of the optimized model. \n",
    "\n",
    "```R\n",
    "\n",
    "# Train-test split \n",
    "set.seed(111)\n",
    "n = nrow(Hitters)\n",
    "folds <- sample(rep(1:K, length=n))\n",
    "CVR.1se <- matrix(NA, n, 19)\n",
    "\n",
    "# Train the model M_k on ith fold \n",
    "for (i in 1:K) {\n",
    "  fit <- regsubsets(Salary~., Hitters[folds!=i, ], nvmax=19)\n",
    "  # Calculate CVE of test sample \n",
    "  for (j in 1:19) {\n",
    "    pred <- predict(fit, Hitters[folds==i, ], id=j)\n",
    "    CVR.1se[folds==i, j] <- (Hitters$Salary[folds==i]-pred)^2\n",
    "  }\n",
    "}\n",
    "\n",
    "# Calculate average based on One-Standard Error rule \n",
    "avg <- apply(CVR.1se, 2, mean)\n",
    "se <- apply(CVR.1se, 2, sd)/sqrt(n)\n",
    "PE <- cbind(avg - se, avg, avg + se)\n",
    "\n",
    "# Visualize test error \n",
    "matplot(1:19, PE, type=\"b\", col=c(1,2,1), lty=c(3,1,3), pch=20,\n",
    "        xlab=\"Number of Predictors\", ylab=\"Cross-Validation Error\")\n",
    "points(which.min(avg), PE[which.min(avg),2],\n",
    "       pch=\"o\",col=\"blue\",cex=2)\n",
    "up <- which(PE[,2] < PE[which.min(PE[,2]),3])\n",
    "points(min(up), PE[min(up),2], pch=\"x\", col=\"blue\", cex=2) \n",
    "```\n",
    "\n",
    "![](Img/Subset_One_Standard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea093f",
   "metadata": {},
   "source": [
    "# 4. Variable Selection Methods \n",
    "\n",
    "- We cannot use subset selection model in $n << p$ (high demensional data). \n",
    "- So a shrinkage method is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f4c9d",
   "metadata": {},
   "source": [
    "## 4.1 Shrinkage\n",
    "\n",
    "- Technique that constrains or regularizes the coeeficient estimates $\\hat{\\beta}$, that shrinks the $\\hat{\\beta}$ towards zero.\n",
    "    - $E(\\hat{\\beta}^{sh}) \\neq \\beta$\n",
    "- Shrinking the $\\hat{\\beta}$ can reduce variance \n",
    "    - $Var(\\hat{\\beta}^{OLS}) >> Var(\\hat{\\beta}^{sh})$\n",
    "- Examples \n",
    "    - Ridge\n",
    "    - Lasso \n",
    "    - Elastic Net : Ridge + Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a07abf",
   "metadata": {},
   "source": [
    "## 4.2 Ridge Regression\n",
    "\n",
    "- $RSS + \\lambda\\sum_{j=1}^{p}\\beta_j^2$\n",
    "- where $\\lambda >= 0$ is a tuning parameter.\n",
    "- For a grid of $\\lambda$ : $\\lambda_{max} = \\lambda_1 > ... > \\lambda_m = \\lambda_{min}$.\n",
    "- The $l_2$-norm of $\\hat{\\beta}$ : $||\\hat{\\beta_{\\lambda_1}}||^2 < ... < ||\\hat{\\beta_{\\lambda_m}}||^2$\n",
    "\n",
    "```R\n",
    "library(glmnet)\n",
    "# model.matrix convert original data into new matrix which form added with intercept.\n",
    "x <- model.matrix(Salary~., Hitters)[, -1] \n",
    "y <- Hitters$Salary\n",
    "\n",
    "# Grid Search for hyper parameter tuning lambda \n",
    "grid <- 10^seq(10, -2, length = 100) \n",
    "# Fit the ridge model : Default grid of lambda \n",
    "ridge.mod <- glmnet(x, y, alpha = 0, lambda=grid) \n",
    "\n",
    "# row for the number of parameters \n",
    "# col for the number of hyperparameter lambda \n",
    "dim(coef(ridge.mod)) \n",
    "ridge.mod$lambda \n",
    "\n",
    "# Calculate l_2 norm of each lambda \n",
    "# If lambda increase, l_2 norm decreaes \n",
    "# If lambda decreaes, l_2 norm increase \n",
    "ridge.mod$lambda[60]\n",
    "coef(ridge.mod)[,60]\n",
    "sqrt(sum(coef(ridge.mod)[-1, 60]^2))\n",
    "\n",
    "# Calculate l2-norm based on lambda \n",
    "l2.norm <- apply(ridge.mod$beta, 2, function(t) sum(t^2))\n",
    "x.axis <- cbind(log(ridge.mod$lambda), l2.norm)\n",
    "colnames(x.axis) <- c(\"log.lambda\", \"L2.norm\")\n",
    "x.axis\n",
    "\n",
    "# Visualize plot\n",
    "par(mfrow=c(1,2))\n",
    "plot(ridge.mod, \"lambda\", label=TRUE)\n",
    "plot(ridge.mod, \"norm\", label=TRUE)\n",
    "```\n",
    "\n",
    "![](Img/ridge1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc57ac3",
   "metadata": {},
   "source": [
    "## 4.3 Lasso Regression\n",
    "\n",
    "- Ridge have disadvantages of including all p predictors in the final model. \n",
    "- What we want to do is variable selection. \n",
    "- Lasso shrinks $\\hat{\\beta}$ towards zero.\n",
    "- $RSS + \\lambda\\sum_{j=1}^{p}|\\beta_j|$\n",
    "- The $l_1$-norm of $\\hat{\\beta}$ : $df(\\hat{\\beta}_{\\lambda_1}) = 0 <  ... < df(\\hat{\\beta}_{\\lambda_m}) = m$\n",
    "    - $df$ is the number of variable which takes part in training model.\n",
    "\n",
    "```R\n",
    "# lasso when the value of argument alpha is 1. \n",
    "lasso.mod <- glmnet(x, y, alpha=1) \n",
    "# the number of default value of lambda is 100. \n",
    "# However, considering complexity of parameter, our model us 80 lambdas.   \n",
    "dim(coef(lasso.mod)) \n",
    "\n",
    "# Find the degree of freedom matrix \n",
    "las <- cbind(lasso.mod$lambda, lasso.mod$df) \n",
    "colnames(las) <- c(\"lambda\", \"df\") \n",
    "las\n",
    "\n",
    "# Find the beta\n",
    "# The sum of beta which is not zero is same with the value of df. \n",
    "dim(lasso.mod$beta)\n",
    "apply(lasso.mod$beta, 2, function(t) sum(t!=0))\n",
    "apply(lasso.mod$beta, 2, function(t) sum(abs(t)))\n",
    "\n",
    "# Calculate l1-norm based on lambda \n",
    "l1.norm <- apply(lasso.mod$beta, 2, function(t) sum(abs(t)))\n",
    "x.axis <- cbind(log(lasso.mod$lambda), l1.norm)\n",
    "colnames(x.axis) <- c(\"log.lambda\", \"L1.norm\")\n",
    "x.axis\n",
    "\n",
    "# Visualize plot\n",
    "par(mfrow=c(1,2))\n",
    "plot(lasso.mod, \"lambda\", label=TRUE)\n",
    "plot(lasso.mod, \"norm\", label=TRUE)\n",
    "```\n",
    "\n",
    "![](Img/lasso1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554c912",
   "metadata": {},
   "source": [
    "# 5. Selecting the Tuning Parameter\n",
    "\n",
    "- Cross-validation provides a simple way to tackle this problem. \n",
    "- Choose a grid of $\\lambda$ values, compute the CVE for each value of $\\lambda$. \n",
    "- Can apply One-Standard rule to Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e77a6",
   "metadata": {},
   "source": [
    "## 5.1 [Ex] Validation Set\n",
    "\n",
    "- alpha = 0 : ridge regression \n",
    "- alpha = 1 : lasso regression \n",
    "\n",
    "```R\n",
    "# Make dataset \n",
    "library(glmnet)\n",
    "library(ISLR) \n",
    "names(Hitters) \n",
    "Hitters <- na.omit(Hitters) \n",
    "\n",
    "set.seed(123)\n",
    "x <- model.matrix(Salary~., Hitters)[, -1] \n",
    "y <- Hitters$Salary\n",
    "\n",
    "# Train-Test Split\n",
    "train <- sample(1:nrow(x), nrow(x)/3) \n",
    "test <- (-train) \n",
    "y.test <- y[test]\n",
    "\n",
    "# Hyperparameter tuning \n",
    "grid <- 10^seq(10, -2, length=100) \n",
    "r1 <- glmnet(x[train, ], y[train], alpha=0, lambda=grid)\n",
    "ss <- 0:(length(r1$lambda)-1) \n",
    "Err <- NULL\n",
    "\n",
    "# Cross validation Error for test sample \n",
    "for (i in 1:length(r1$lambda)) { \n",
    "    r1.pred <- predict(r1, s=ss[i], newx=x[test, ])\n",
    "    Err[i] <- mean((r1.pred - y.test)^2) \n",
    "} \n",
    "wh <- which.min(Err) \n",
    "lam.opt <- r1$lambda[wh] \n",
    "\n",
    "# Get full model with optimized hyperparmeter \n",
    "r.full <- glmnet(x, y, alpha=0, lambda=grid) \n",
    "r.full$beta[, wh] \n",
    "predict(r.full, type=\"coefficients\", s=lam.opt) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b22a4",
   "metadata": {},
   "source": [
    "## 5.2 [Ex] K-fold Cross Validation\n",
    "\n",
    "```R\n",
    "set.seed(1234)\n",
    "cv.r <- cv.glmnet(x, y, alpha=0, nfolds=10)\n",
    "names(cv.r) \n",
    "# cvm : The mean value of cross validation -> CVE \n",
    "# cvsd : The standard deviation of cross validation -> One-standard error \n",
    "# cvup : The upperbound of CVE -> cvm + cvsd \n",
    "# cvlo : The lowerbound of CVE -> cvm - cvsd \n",
    "# lambda.min : The lambda which optimize input model \n",
    "# lambda.1se : The lambda which optimize imput model based on one-standard error \n",
    "\n",
    "cbind(cv.r$cvlo, cv.r$cvm, cv.r$cvup)\n",
    "# Scatter plot based on One-Standard error \n",
    "# left vertix line : log(lambda.min) \n",
    "# right vertix line(more shrinked model) : log(lambda.1se) \n",
    "plot(cv.r) \n",
    "\n",
    "which(cv.r$lambda==cv.r$lambda.min)\n",
    "which(cv.r$lambda==cv.r$lambda.1se)\n",
    "# 100, 54 -> lambda.min < lambda.1se \n",
    "\n",
    "b.min <- predict(cv.r, type=\"coefficients\", s=cv.r$lambda.min)\n",
    "b.1se <- predict(cv.r, type=\"coefficients\", s=cv.r$lambda.1se)\n",
    "\n",
    "# calculate l1-norm\n",
    "# calculate sum(b.min!=0) - 1 to get l2-norm \n",
    "cbind(b.min, b.1se)\n",
    "c(sum(b.min[-1]^2), sum(b.1se[-1]^2))\n",
    "# sum(b.min[-1]^2) > sum(b.1se[-1]^2) \n",
    "```\n",
    "\n",
    "![](Img/ridge2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e0a04",
   "metadata": {},
   "source": [
    "# 6.1 Consider reality \n",
    "\n",
    "## 6.1 The Bias-Variance tradeoff\n",
    "\n",
    "- If lambda axis increases to the right \n",
    "- Overfittng vs Underfitting \n",
    "- (Low bias + High variance) vs (High bias + Low variance)\n",
    "- (l1-norm, l2-norm increase) vs (l1-norm, l2-norm decrease) \n",
    "- $\\lambda$ decrease vs $\\lambda$ increase\n",
    "\n",
    "## 6.2 Comparison between Lasso and Ridge \n",
    "\n",
    "- If nonzero coefficient are large, ridge is better. \n",
    "- If nonzero coefficient are small, lasso is better. \n",
    "- In high-dimensional data where spares model is assummed, lasso perform better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a4b85",
   "metadata": {},
   "source": [
    "# 7. Regularization Methods \n",
    "\n",
    "- Regularization methods are based on a penalized likelihood : \n",
    "- $Q_{\\lambda}(\\beta_0, \\beta) = -l(\\beta_0, \\beta) + p_{\\lambda}(\\beta)$ \n",
    "- $(\\hat{\\beta_0}, \\hat{\\beta}) = arg min Q_{\\lambda}(\\beta_0, \\beta)$ \n",
    "- Penalized likelihood for quantitive \n",
    "    - Linear regression model : $y_i = \\beta_0 + x_i^T \\beta + \\epsilon_i$\n",
    "    - l1-norm : $\\lambda \\sum(\\hat{\\beta}^2)$ \n",
    "    - l2-norm : $\\lambda \\sum|\\hat{\\beta}|$\n",
    "    - $Q_{\\lambda}(\\beta_0, \\beta) = -l(\\beta_0, \\beta) + p_{\\lambda}(\\beta) = \\frac{1}{2}\\sum_{i=1}^{n}(y_i - \\beta_0 + x_i^T \\beta)^2 +  p_{\\lambda}(\\beta)$\n",
    "- Penalized likelihood for binary \n",
    "    - CVE based on deviance : $CVE = \\frac{1}{n}\\sum_{k=1}^K -2\\sum_{i \\in C_k}(y_i \\log{\\hat{p_i}^{[-k]} + (1 - y_i) \\log{(1-\\hat{p_i}^{[-k]})})} $ \n",
    "        - if type=\"response\" : $p_i(\\beta_0, \\beta) = \\frac{e^{\\beta_0 + x_i^T \\beta}}{1 + e^{\\beta_0 + x_i^T \\beta}}$\n",
    "    - CVE based on classification error : $CVE = \\frac{1}{n}\\sum\\sum I(y_i - \\hat{y_i})^{[-k]}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff1d3a",
   "metadata": {},
   "source": [
    "## 7.1 [Ex] Heart Data \n",
    "\n",
    "```R\n",
    "# Importing Datasets \n",
    "library(glmnet)\n",
    "url.ht <- \"https://www.statlearning.com/s/Heart.csv\"\n",
    "Heart <- read.csv(url.ht, h=T)\n",
    "summary(Heart)\n",
    "\n",
    "# Preprocessing Data \n",
    "Heart <- Heart[, colnames(Heart)!=\"X\"]\n",
    "Heart[,\"Sex\"] <- factor(Heart[,\"Sex\"], 0:1, c(\"female\", \"male\"))\n",
    "Heart[,\"Fbs\"] <- factor(Heart[,\"Fbs\"], 0:1, c(\"false\", \"true\"))\n",
    "Heart[,\"ExAng\"] <- factor(Heart[,\"ExAng\"], 0:1, c(\"no\", \"yes\"))\n",
    "Heart[,\"ChestPain\"] <- as.factor(Heart[,\"ChestPain\"])\n",
    "Heart[,\"Thal\"] <- as.factor(Heart[,\"Thal\"])\n",
    "Heart[,\"AHD\"] <- as.factor(Heart[,\"AHD\"])\n",
    "summary(Heart)\n",
    "dim(Heart)\n",
    "sum(is.na(Heart))\n",
    "Heart <- na.omit(Heart)\n",
    "dim(Heart)\n",
    "summary(Heart)\n",
    "\n",
    "# Train model \n",
    "## Logistic Regression\n",
    "# Add dummy variable to original matrix x wihtout intercept \n",
    "x <- model.matrix(AHD ~., Heart)[,-1]\n",
    "y <- Heart$AHD\n",
    "\n",
    "# Train model \n",
    "g1 <- glmnet(x, y, family=\"binomial\")\n",
    "\n",
    "# Comparison lambda - coefficient, l1-norm - coefficient \n",
    "par(mfrow=c(1,2))\n",
    "plot(g1, \"lambda\", label=TRUE)\n",
    "plot(g1, \"norm\", label=TRUE)\n",
    "df <- cbind(g1$lambda, g1$df)\n",
    "colnames(df) <- c(\"lambda\", \"nonzero\")\n",
    "rownames(df) <- colnames(g1$beta)\n",
    "df\n",
    "```\n",
    "\n",
    "![](Img/heart1.png)\n",
    "- If lambda decreases, the number of active coefficients increase. \n",
    "- If l1-norm increase(lambda decrease), the number of active coefficeints increase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc83b4",
   "metadata": {},
   "source": [
    "```R\n",
    "# Make evaluation : 10 folds \n",
    "set.seed(1234) \n",
    "K <- 10 \n",
    "n <- length(y) \n",
    "fold <- sample(rep(1:K, length.out=n)) \n",
    "lam <- g1$lambda \n",
    "MSE <- matrix(0, n, length(lam)) \n",
    "for (i in 1:K) {\n",
    "  test <- fold==i\n",
    "  tran <- fold!=i \n",
    "  g <- glmnet(x[tran, ], y[tran], family=\"binomial\", lambda=lam)\n",
    "  prob <- predict(g, x[test, ], s=lam, type=\"response\")\n",
    "  yval <- y[test]==\"Yes\"\n",
    "  MSE[test, ] <- -2*(yval*log(prob) + (1-yval)*log(1-prob))\n",
    "}\n",
    "CVE <- apply(MSE, 2, mean)\n",
    "\n",
    "# Visualize CVE metrics \n",
    "par(mfrow=c(1,1))\n",
    "plot(log(lam), CVE, type=\"b\", xlab=\"log lambda\", ylab=\"CV errors\")\n",
    "abline(v=log(lam)[which.min(CVE)], col=\"red\", lty=2)\n",
    "\n",
    "# Make final model : With full training set \n",
    "lam[which.min(CVE)]\n",
    "coef(g, s=lam[which.min(CVE)])\n",
    "g1 <- glmnet(x, y, family=\"binomial\", lambda=lam[which.min(CVE)])\n",
    "coef(g1)\n",
    "```\n",
    "\n",
    "![](Img/heart2.png)\n",
    "\n",
    "- K-fold without using cv.glmnet. \n",
    "- MSE has been used for model evaluation metrics.\n",
    "- model.matrix function convert original data into categorical encoded columns and intercepts. \n",
    "- To apply this metrx to glmnet, we need to input matrix without intercept.(beacuse inner argument of intercept is True).\n",
    "- However, if we calculate prediction from the result of coef function, then we need to multiply with matrix with intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad69e8",
   "metadata": {},
   "source": [
    "## 7.2 [Ex] Heart Data with automatic CV  \n",
    "\n",
    "```R\n",
    "set.seed(123)\n",
    "par(mfrow=c(1,3))\n",
    "# Error metric : Deviance \n",
    "# foldID shows the restricted fold -> don't need to use nfolds parameters\n",
    "gcv1 <- cv.glmnet(x, y, family=\"binomial\", lambda=lam,\n",
    "nfolds=5, type.measure=\"deviance\")\n",
    "plot(gcv1)\n",
    "\n",
    "# Error metric : Classification error \n",
    "gcv2 <- cv.glmnet(x, y, family=\"binomial\", lambda=lam,\n",
    "nfolds=5, type.measure=\"class\")\n",
    "plot(gcv2)\n",
    "\n",
    "# Error metric : ROC-AUC score\n",
    "gcv3 <- cv.glmnet(x, y, family=\"binomial\", lambda=lam,\n",
    "nfolds=5, type.measure=\"auc\")\n",
    "plot(gcv3)\n",
    "\n",
    "c(gcv1$lambda.min, gcv1$lambda.1se)\n",
    "c(gcv2$lambda.min, gcv2$lambda.1se)\n",
    "c(gcv3$lambda.min, gcv3$lambda.1se)\n",
    "g0 <- glmnet(x, y, family=\"binomial\", lambda=lam)\n",
    "coef(g0, s=c(gcv1$lambda.min, gcv2$lambda.min, gcv3$lambda.min))\n",
    "coef(g0, s=c(gcv1$lambda.1se, gcv2$lambda.1se, gcv3$lambda.1se))\n",
    "```\n",
    "\n",
    "![](Img/heart3.png) \n",
    "\n",
    "- Three plots are written based on one-standard error. \n",
    "- The left vertical line is the value of gcvl\\$lambda.min.\n",
    "- The right vertical line is the value of gcvl\\$labmda.1se."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c27ecf",
   "metadata": {},
   "source": [
    "# 8. Simulation Study : Prediction Performance \n",
    "\n",
    "- If $X$ has $n \\times p (200 \\times 2000)$ size, we need to find which variables are selected and which variable affects target most(coefficients). \n",
    "- So, we need to consider variable models predicting well. \n",
    "    - M1 : $\\hat{\\beta}^{lasso} + \\lambda_{min}$ \n",
    "    - M2 : $\\hat{\\beta}^{lasso} + \\lambda_{1se}$ \n",
    "    - M3 : $\\hat{\\beta}^{lasso} + \\lambda_{min} + \\hat{\\beta}^{ols}$ \n",
    "    - M4 : $\\hat{\\beta}^{lasso} + \\lambda_{1se} + \\hat{\\beta}^{ols}$ \n",
    "    - M5 : $\\hat{\\beta}^{ols}[1:20]$\n",
    "- After training model and with their regression coefficients, choose the best model with the lowest $MSE_{test}$.\n",
    "\n",
    "## 8.1 [Ex] Quantitative Outcome\n",
    "\n",
    "**Generate $X$ and $Y$** \n",
    "\n",
    "```R\n",
    "# install.packages('glmnet')\n",
    "library(glmnet)\n",
    "\n",
    "# Generate X matrix and Y vector\n",
    "sim.fun <- function(n, p, beta, family=c(\"gaussian\", \"binomial\")) {\n",
    "  family <- match.arg(family)\n",
    "  if (family==\"gaussian\") {\n",
    "    x <- matrix(rnorm(n*p), n, p)\n",
    "    y <- x %*% beta + rnorm(n)\n",
    "  }\n",
    "  else {\n",
    "    x <- matrix(rnorm(n*p), n, p)\n",
    "    xb <- x %*% beta\n",
    "    z <- exp(xb) / (1+exp(xb))\n",
    "    u <- runif(n)\n",
    "    y <- rep(0, n)\n",
    "    y[z > u] <- 1\n",
    "  }\n",
    "  list(x=x, y=y)\n",
    "}\n",
    "\n",
    "# Configure dimension of n, p and beta(모수)\n",
    "set.seed(1234)\n",
    "n <- 200\n",
    "p <- 2000\n",
    "beta <- rep(0, p)\n",
    "beta[1:20] <- runif(20, -1, 1)\n",
    "\n",
    "# Generate x and y \n",
    "sim <- sim.fun(n, p, beta)\n",
    "x <- sim$x; y <- sim$y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8ad36",
   "metadata": {},
   "source": [
    "**Regression Coefficients based on Model1 and Model2** \n",
    "\n",
    "```R\n",
    "# Fit the lasso with two different lambda values\n",
    "# b hat is inferred regression coefficients : M1, M2 \n",
    "g <- cv.glmnet(x, y, alpha=1, nfolds = 10)\n",
    "bhat1 <- coef(g, s=\"lambda.min\")\n",
    "bhat2 <- coef(g, s=\"lambda.1se\")\n",
    "# Check coefficients with value is not 0. \n",
    "wh1 <- which(as.matrix(bhat1)!=0)\n",
    "w1 <- wh1[-1]-1\n",
    "wh2 <- which(as.matrix(bhat2)!=0)\n",
    "w2 <- wh2[-1]-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd147f",
   "metadata": {},
   "source": [
    "**Regression Coefficients based on Model3, Model4, and Model5** \n",
    "\n",
    "```R\n",
    "# Compute ordinary least square estimates (unbiased estimates)\n",
    "bhat3 <- bhat4 <- bhat5 <- rep(0, p+1)\n",
    "bhat3[wh1] <- lm(y ~ x[, w1])$coef\n",
    "bhat4[wh2] <- lm(y ~ x[, w2])$coef\n",
    "bhat5[1:21] <- lm(y ~ x[, 1:20])$coef\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57aaa28",
   "metadata": {},
   "source": [
    "**Calculate Test Error based on MSE among Models** \n",
    "\n",
    "```R\n",
    "set.seed(56789)\n",
    "# Generate test sets\n",
    "test <- sim.fun(n, p, beta)\n",
    "xt <- cbind(1, test$x)\n",
    "yt <- test$y\n",
    "\n",
    "# Test set prediction errors of 6 coefficient estimates\n",
    "mean((yt - xt %*% bhat1)^2) # lasso_lambda.min (M1)\n",
    "mean((yt - xt %*% bhat2)^2) # lasso_lambda.1se (M2)\n",
    "mean((yt - xt %*% bhat3)^2) # least square_lambda.min (M3)\n",
    "mean((yt - xt %*% bhat4)^2) # least square_lambda.1se (M4)\n",
    "mean((yt - xt %*% bhat5)^2) # least square_nonzero beta (M5)\n",
    "mean((yt - xt %*% c(0, beta))^2) # true beta (M6)\n",
    "\n",
    "# Calculate TE repeatedly\n",
    "set.seed(1)\n",
    "# Generate new test sets 100 times\n",
    "K <- 100\n",
    "pred <- matrix(NA, K, 6)\n",
    "for (i in 1:K) {\n",
    "    test <- sim.fun(n, p, beta)\n",
    "    xt <- cbind(1, test$x)\n",
    "    yt <- test$y\n",
    "\n",
    "    pred[i, 1] <- mean((yt - xt %*% bhat1)^2)\n",
    "    pred[i, 2] <- mean((yt - xt %*% bhat2)^2)\n",
    "    pred[i, 3] <- mean((yt - xt %*% bhat3)^2)\n",
    "    pred[i, 4] <- mean((yt - xt %*% bhat4)^2)\n",
    "    pred[i, 5] <- mean((yt - xt %*% bhat5)^2)\n",
    "    pred[i, 6] <- mean((yt - xt %*% c(0, beta))^2)\n",
    "}\n",
    "\n",
    "apply(pred, 2, mean)\n",
    "boxplot(pred, col=c(2,2,4,4,3,\"orange\"), boxwex=0.6,\n",
    "names=c(\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\"),\n",
    "ylab=\"Prediction Error\")            \n",
    "```\n",
    "\n",
    "![](Img/Simulation1.png)\n",
    "- We can see that lasso model didn't select accurate variables rather than ols model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d9da",
   "metadata": {},
   "source": [
    "## 8.2 [Ex] Binary Outcome \n",
    "\n",
    "**Generate $X$ and $Y$**\n",
    "\n",
    "```R\n",
    "set.seed(111)\n",
    "n <- 200\n",
    "p <- 2000\n",
    "beta <- rep(0, p)\n",
    "beta[1:20] <- runif(20, -1, 1)\n",
    "sim <- sim.fun(n, p, beta, family=\"binomial\")\n",
    "x <- sim$x; y <- sim$y\n",
    "```\n",
    "\n",
    "**Classification Error Function** \n",
    "\n",
    "```R\n",
    "## Classification Error\n",
    "class.fun <- function(test.x, test.y, beta, k=0.5) {\n",
    "    # xb : calculate x % coefficients\n",
    "    xb <- test.x %*% beta\n",
    "    # exb : inferred probability of xb \n",
    "    exb <- exp(xb) / (1 + exp(xb))\n",
    "    y <- rep(0, length(test.y))\n",
    "    y[as.logical(exb > k)] <- 1\n",
    "    min(mean(test.y!=y), mean(test.y!=(1-y)))\n",
    "}\n",
    "```\n",
    "\n",
    "**Training Models 1 ~ 5** \n",
    "\n",
    "```R\n",
    "g <- cv.glmnet(x, y, alpha=1, nfolds = 10, family=\"binomial\")\n",
    "bhat1 <- coef(g, s=\"lambda.min\")\n",
    "bhat2 <- coef(g, s=\"lambda.1se\")\n",
    "wh1 <- which(as.matrix(bhat1)!=0)\n",
    "wh2 <- which(as.matrix(bhat2)!=0)\n",
    "bhat3 <- bhat4 <- bhat5 <- rep(0, p+1)\n",
    "w1 <- wh1[-1]-1; w2 <- wh2[-1]-1\n",
    "bhat3[wh1] <- glm(y ~ x[, w1], family=\"binomial\")$coef\n",
    "bhat4[wh2] <- glm(y ~ x[, w2], family=\"binomial\")$coef\n",
    "bhat5[1:21] <- glm(y ~ x[, 1:20], family=\"binomial\")$coef\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b075bc",
   "metadata": {},
   "source": [
    "**Calculate Test Error based on Missclassification Rate** \n",
    "\n",
    "```R\n",
    "# Generate test sets\n",
    "set.seed(56789)\n",
    "test <- sim.fun(n, p, beta, family=\"binomial\")\n",
    "xt <- cbind(1, test$x); yt <- test$y\n",
    "\n",
    "# Prediction error comparison\n",
    "class.fun(xt, yt, bhat1) # lasso_lambda.min (M1)\n",
    "class.fun(xt, yt, bhat2) # lasso_lambda.1se (M2)\n",
    "class.fun(xt, yt, bhat3) # least square_lambda.min (M3)\n",
    "class.fun(xt, yt, bhat4) # least square_lambda.1se (M4)\n",
    "class.fun(xt, yt, bhat5) # least square_nonzero beta (M5)\n",
    "class.fun(xt, yt, c(0, beta)) # true beta (M6)\n",
    "\n",
    "# Calculate TE repeatedly\n",
    "set.seed(35791)\n",
    "\n",
    "# Generate new test sets 100 times\n",
    "K <- 100\n",
    "pred <- matrix(NA, K, 6)\n",
    "for (i in 1:K) {\n",
    "    test <- sim.fun(n, p, beta, family=\"binomial\")\n",
    "    xt <- cbind(1, test$x)\n",
    "    yt <- test$y\n",
    "\n",
    "    pred[i, 1] <- class.fun(xt, yt, bhat1)\n",
    "    pred[i, 2] <- class.fun(xt, yt, bhat2)\n",
    "    pred[i, 3] <- class.fun(xt, yt, bhat3)\n",
    "    pred[i, 4] <- class.fun(xt, yt, bhat4)\n",
    "    pred[i, 5] <- class.fun(xt, yt, bhat5)\n",
    "    pred[i, 6] <- class.fun(xt, yt, c(0, beta))\n",
    "}\n",
    "\n",
    "apply(pred, 2, mean)\n",
    "boxplot(pred, col=c(2,2,4,4,3,\"orange\"), boxwex=0.6,\n",
    "names=c(\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\"),\n",
    "ylab=\"Prediction Error\")  \n",
    "```\n",
    "\n",
    "![](Img/Simulation2.png)\n",
    "\n",
    "- With accurate variable selection(using ols model), we can get better test error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a97ca",
   "metadata": {},
   "source": [
    "# 9. Regularization Methods \n",
    "\n",
    "- $Q_{\\lambda}(\\beta_0, \\beta) = -l(\\beta_0, \\beta) + p_{\\lambda}(\\beta)$\n",
    "\n",
    "## 9.1 The negative log-likelihood function\n",
    "\n",
    "- Quantitative outcome: least square loss function\n",
    "- Binary outcome: logistic likelihood\n",
    "- Matched case-control outcome: conditional logistic likelihood\n",
    "- Count outcome: Poisson likelihood\n",
    "- Qualitative outcome: Multinomial likelihood\n",
    "- Survival outcome: Cox partial likelihood\n",
    "\n",
    "## 9.2 Type of Penalty Functions\n",
    "- Convex penalty functions\n",
    "    - Lasso (Tibshirani, JRSS, 1996)\n",
    "    - Fused lasso (Tibshirani et al. JRSS, 2005)\n",
    "    - Adaptive lasso (Zou, JASA, 2006)\n",
    "    - Elastic-net (Zou and Hastie, JRSS, 2005)\n",
    "- Non-convex penalty functions\n",
    "    - lq-norm penalty with 0 < q < 1\n",
    "    - Smoothly clipped absolute deviation (SCAD) (Fan and Li, JASA, 2005)\n",
    "    - Minimax concave penalty (MCP) (Zhang, AOS, 2010)\n",
    "- Group structure penalty functions\n",
    "    - Group lasso (Yuan and Lin, JRSS, 2006)\n",
    "    - Graph-constrained regularization (Li and Li, AOAS 2010)\n",
    "    - Sparse group lasso (Simon et al. JGCS 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09dda0",
   "metadata": {},
   "source": [
    "# 10. Elastic-Net Regression \n",
    "\n",
    "- Lasso penalty function($l1$-norm) \n",
    "    - If $p > n$, lasso selects at most $n$ variables. \n",
    "    - Lasso is indifferent to highly correlated variables and tends to pick only one variable. \n",
    "- Ridge penalty function($l2$-norm) \n",
    "    - If cannot perform variable selection.\n",
    "    - Shrinks correlated features to each other. \n",
    "- Elastic-net regularization \n",
    "    - Combine Lasso and Ridge \n",
    "    - $p_{\\lambda}(\\beta) = \\lambda \\alpha \\sum_{j=1}^p |\\beta_j| + \\lambda(1 - \\alpha)\\sum_{j=1}^p \\beta_j^2$ \n",
    "    - $\\alpha$ : mixing proportion \n",
    "        - Lasso if $\\alpha = 1$\n",
    "        - Ridge if $\\alpha = 0$\n",
    "    - Minimize the penalized log-likelihood where tuning parameters $\\alpha$ and $\\lambda$ are fixed.\n",
    "    \n",
    "## 10.1 [Ex] Golub Data \n",
    "\n",
    "**Prepare Dataset golub** \n",
    "\n",
    "```R\n",
    "# 1. importing package and dataset \n",
    "\n",
    "# Install bioconductor package ’golubEsets’\n",
    "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"golubEsets\")\n",
    "library(golubEsets)\n",
    "data(Golub_Merge)\n",
    "\n",
    "# Golub data\n",
    "?Golub_Merge\n",
    "dim(Golub_Merge)\n",
    "varLabels(Golub_Merge)\n",
    "Golub_Merge$ALL.AML\n",
    "table(Golub_Merge$ALL.AML)\n",
    "Golub_Merge$Gender\n",
    "\n",
    "# Expression data\n",
    "dim(exprs(Golub_Merge))\n",
    "head(exprs(Golub_Merge))\n",
    "tail(exprs(Golub_Merge))\n",
    "\n",
    "# Transpose the predictor x into n by p matrix\n",
    "x <- t(as.matrix(exprs(Golub_Merge)))\n",
    "y <- Golub_Merge$ALL.AML\n",
    "dim(x)\n",
    "sum(is.na(x))\n",
    "```\n",
    "\n",
    "**Training models : Ridge and Lasso** \n",
    "\n",
    "```R\n",
    "# Model1 : Ridge regression \n",
    "g0 <- glmnet(x, y, alpha=0, family=\"binomial\")\n",
    "par(mfrow=c(1,2))\n",
    "plot(g0, \"lambda\")\n",
    "plot(g0, \"norm\")\n",
    "\n",
    "# Model2 : Lasso regression \n",
    "g1 <- glmnet(x, y, alpha=1, family=\"binomial\")\n",
    "par(mfrow=c(1,2))\n",
    "plot(g1, \"lambda\")\n",
    "plot(g1, \"norm\")\n",
    "\n",
    "# Cross Validation Lasso \n",
    "set.seed(12345)\n",
    "gvc <- cv.glmnet(x, y, alpha=1, family=\"binomial\", nfolds=5)\n",
    "gvc$lambda.min\n",
    "gvc$lambda.1se\n",
    "plot(gvc)\n",
    "fit1 <- coef(gvc, s=\"lambda.min\")\n",
    "fit2 <- coef(gvc, s=\"lambda.1se\")\n",
    "c(sum(as.matrix(fit1)!=0), sum(as.matrix(fit2)!=0))\n",
    "w1 <- which(as.matrix(fit1)!=0)\n",
    "w2 <- which(as.matrix(fit2)!=0)\n",
    "data.frame(name=colnames(x)[w1], beta=fit1[w1])\n",
    "data.frame(name=colnames(x)[w2], beta=fit1[w2])\n",
    "```\n",
    "\n",
    "![](Img/Elastic1.png)\n",
    "![](Img/Elastic2.png)\n",
    "\n",
    "- In Ridge regression, all variables are selected for training.\n",
    "- In Lasso regression, only subset variables are selected for training.\n",
    "- In Lasso with Cross Valdiation, we can select opmimized number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f932fa3",
   "metadata": {},
   "source": [
    "**Training model : Elastic-Net** \n",
    "\n",
    "```R\n",
    "# Elastic-Net regression\n",
    "ge <- glmnet(x, y, alpha=0.5, family=\"binomial\")\n",
    "ge$df\n",
    "ge$lambda\n",
    "plot(ge, \"lambda\")\n",
    "\n",
    "# Elastic-Net regression with K-folds Cross Validation \n",
    "set.seed(111)\n",
    "gecv <- cv.glmnet(x, y, alpha=0.5, family=\"binomial\", nfolds=5)\n",
    "plot(gecv)\n",
    "fit3 <- coef(gecv, s=\"lambda.min\")\n",
    "fit4 <- coef(gecv, s=\"lambda.1se\")\n",
    "c(sum(as.matrix(fit3)!=0), sum(as.matrix(fit4)!=0))\n",
    "w3 <- which(as.matrix(fit3)!=0)\n",
    "w4 <- which(as.matrix(fit4)!=0)\n",
    "data.frame(name=colnames(x)[w3], beta=fit3[w3])\n",
    "data.frame(name=colnames(x)[w4], beta=fit4[w4])\n",
    "```\n",
    "\n",
    "![](Img/Elastic3.png)\n",
    "\n",
    "- In Elastic-Net regression, the number of selected variables increases from 27 to 91. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4256e",
   "metadata": {},
   "source": [
    "**Calculate Test Error among Models based on Classification Error** \n",
    "\n",
    "```R\n",
    "# Seperate training sets and test sets\n",
    "Golub_Merge$Samples\n",
    "tran <- Golub_Merge$Samples < 39\n",
    "test <- !tran\n",
    "c(sum(tran), sum(test))\n",
    "\n",
    "# Calculate Test error from Lasso  \n",
    "set.seed(123)\n",
    "g1 <- cv.glmnet(x, y, alpha=1, family=\"binomial\", K=5,\n",
    "subset=tran)\n",
    "fit1 <- coef(g1, s=\"lambda.min\")\n",
    "fit2 <- coef(g1, s=\"lambda.1se\")\n",
    "c(sum(as.matrix(fit1)!=0), sum(as.matrix(fit2)!=0))\n",
    "p1 <- predict(g1, x[test,], s=\"lambda.min\", type=\"class\")\n",
    "p2 <- predict(g1, x[test,], s=\"lambda.1se\", type=\"class\")\n",
    "\n",
    "# Confusion Matrix from 2 models \n",
    "table(p1, y[test])\n",
    "table(p2, y[test])\n",
    "\n",
    "# Calculate Test error from Elastic-Net\n",
    "set.seed(1234)\n",
    "g2 <- cv.glmnet(x, y, alpha=0.5, family=\"binomial\", K=5,\n",
    "subset=tran)\n",
    "fit3 <- coef(g2, s=\"lambda.min\")\n",
    "fit4 <- coef(g2, s=\"lambda.1se\")\n",
    "c(sum(as.matrix(fit3)!=0), sum(as.matrix(fit4)!=0))\n",
    "p3 <- predict(g2, x[test,], s=\"lambda.min\", type=\"class\")\n",
    "p4 <- predict(g2, x[test,], s=\"lambda.1se\", type=\"class\")\n",
    "\n",
    "# Confusion Matrix from 2 models \n",
    "table(p3, y[test])\n",
    "table(p4, y[test])\n",
    "```\n",
    "\n",
    "- In model1(p1), there is no missclassified prediction.\n",
    "- In model2(p2), there is only one missclassified prediction. \n",
    "- Using Elastic-Net regression, the number of selected variables are greater than using lasso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9e371",
   "metadata": {},
   "source": [
    "**50 Simulation replications** \n",
    "\n",
    "```R\n",
    "set.seed(111)\n",
    "K <- 50\n",
    "ERR <- DF <- array(0, c(K, 4))\n",
    "for (i in 1:K) {\n",
    "    # Train-Test Split \n",
    "    tran <- as.logical(rep(0, 72))\n",
    "    tran[sample(1:72, 38)] <- TRUE\n",
    "    test <- !tran\n",
    "    \n",
    "    # Training model : lasso vs elastic-net \n",
    "    g1 <- cv.glmnet(x, y, alpha=1, family=\"binomial\", K=5, subset=tran)\n",
    "    g2 <- cv.glmnet(x, y, alpha=0.5, family=\"binomial\", K=5, subset=tran)\n",
    "    \n",
    "    # Calculate probability of prediction \n",
    "    p1 <- predict(g1, x[test,], s=\"lambda.min\", type=\"class\")\n",
    "    p2 <- predict(g1, x[test,], s=\"lambda.1se\", type=\"class\")\n",
    "    p3 <- predict(g2, x[test,], s=\"lambda.min\", type=\"class\")\n",
    "    p4 <- predict(g2, x[test,], s=\"lambda.1se\", type=\"class\")\n",
    "    \n",
    "    # Calculate Degree of freedom (The number of selected variables) \n",
    "    DF[i, 1] <- sum(coef(g1, s=\"lambda.min\")!=0)\n",
    "    DF[i, 2] <- sum(coef(g1, s=\"lambda.1se\")!=0)\n",
    "    DF[i, 3] <- sum(coef(g2, s=\"lambda.min\")!=0)\n",
    "    DF[i, 4] <- sum(coef(g2, s=\"lambda.1se\")!=0)\n",
    "    \n",
    "    # Calculate Missclassification Error\n",
    "    ERR[i, 1] <- sum(p1!=y[test])/sum(test)\n",
    "    ERR[i, 2] <- sum(p2!=y[test])/sum(test)\n",
    "    ERR[i, 3] <- sum(p3!=y[test])/sum(test)\n",
    "    ERR[i, 4] <- sum(p4!=y[test])/sum(test)\n",
    "}\n",
    "apply(ERR, 2, mean)\n",
    "DF\n",
    "apply(DF, 2, var)\n",
    "```\n",
    "\n",
    "- The number of selected variables among models are in order Elastic-net + lambda.min, Elastic-net + lambda.1se, Lasso + lambda.min, Lasso + lambda.1se"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "548.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
